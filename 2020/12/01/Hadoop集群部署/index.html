<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/gg.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/gg.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/gg.png">
  <link rel="mask-icon" href="/images/gg.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"guozenghuang.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="Hadoop是一种分布式数据和计算的框架。">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop集群部署">
<meta property="og:url" content="https://guozenghuang.github.io/2020/12/01/Hadoop%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/index.html">
<meta property="og:site_name" content="guozenghuang">
<meta property="og:description" content="Hadoop是一种分布式数据和计算的框架。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://guozenghuang.github.io/images/profile/hadoop.png">
<meta property="og:image" content="https://guozenghuang.github.io/images/hadoop/hadoop_cluster.png">
<meta property="og:image" content="https://guozenghuang.github.io/images/hadoop/hadoop_overview.png">
<meta property="og:image" content="https://guozenghuang.github.io/images/hadoop/hadoop_summary.png">
<meta property="og:image" content="https://guozenghuang.github.io/images/hadoop/hadoop_jobhistory.png">
<meta property="article:published_time" content="2020-12-01T14:00:03.000Z">
<meta property="article:modified_time" content="2021-08-01T14:00:03.000Z">
<meta property="article:author" content="guozenghuang">
<meta property="article:tag" content="Linux">
<meta property="article:tag" content="cluster">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://guozenghuang.github.io/images/profile/hadoop.png">

<link rel="canonical" href="https://guozenghuang.github.io/2020/12/01/Hadoop%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Hadoop集群部署 | guozenghuang</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">guozenghuang</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">知识的岛屿越大,无知的海岸线就越长。</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签<span class="badge">30</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档<span class="badge">31</span></a>

  </li>
        <li class="menu-item menu-item-github">

    <a href="https://github.com/guozenghuang" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>

  </li>
        <li class="menu-item menu-item-mail">

    <a href="mailto:guozh94@outlook.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>Mail</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://guozenghuang.github.io/2020/12/01/Hadoop%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="guozenghuang">
      <meta itemprop="description" content="一个94年程序员的个人学习小站">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="guozenghuang">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop集群部署
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-01 22:00:03" itemprop="dateCreated datePublished" datetime="2020-12-01T22:00:03+08:00">2020-12-01</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2021-08-01 22:00:03" itemprop="dateModified" datetime="2021-08-01T22:00:03+08:00">2021-08-01</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><img src="/images/profile/hadoop.png" alt="hadoop"></p>
<h2 id="Hadoop是一种分布式数据和计算的框架。"><a href="#Hadoop是一种分布式数据和计算的框架。" class="headerlink" title="Hadoop是一种分布式数据和计算的框架。"></a>Hadoop是一种分布式数据和计算的框架。</h2><span id="more"></span>

<hr>
<h3 id="服务器基础配置"><a href="#服务器基础配置" class="headerlink" title="服务器基础配置"></a>服务器基础配置</h3><h4 id="三台机器更改主机名"><a href="#三台机器更改主机名" class="headerlink" title="三台机器更改主机名"></a>三台机器更改主机名</h4><ul>
<li>三台机器执行以下命令更改主机名</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hostname</span><br></pre></td></tr></table></figure>

<ul>
<li>第一台机器更改内容</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node01.hadoop.com</span><br></pre></td></tr></table></figure>

<ul>
<li>第二台机器更改内容</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node02.hadoop.com</span><br></pre></td></tr></table></figure>

<ul>
<li>第三台机器更改内容</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">node03.hadoop.com</span><br></pre></td></tr></table></figure>

<h4 id="三台机器做主机名与IP地址的映射"><a href="#三台机器做主机名与IP地址的映射" class="headerlink" title="三台机器做主机名与IP地址的映射"></a>三台机器做主机名与IP地址的映射</h4><ul>
<li>三台机器执行以下命令更改主机名与IP地址的映射</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hosts</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.51.100 node01.hadoop.com node01</span><br><span class="line">192.168.51.110 node02.hadoop.com node02</span><br><span class="line">192.168.51.120 node03.hadoop.com node03 </span><br></pre></td></tr></table></figure>

<p><strong>注意：根据自己的实际情况，修改ip地址</strong></p>
<h4 id="三台机器时钟同步"><a href="#三台机器时钟同步" class="headerlink" title="三台机器时钟同步"></a>三台机器时钟同步</h4><h5 id="方式一：通过网络进行时钟同步"><a href="#方式一：通过网络进行时钟同步" class="headerlink" title="方式一：通过网络进行时钟同步"></a>方式一：通过网络进行时钟同步</h5><p><strong>通过网络连接外网进行时钟同步,必须保证虚拟机连上外网</strong></p>
<ul>
<li>三台机器都安装ntpdate</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ntpdate</span><br></pre></td></tr></table></figure>

<ul>
<li>阿里云时钟同步服务器</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ntpdate ntp4.aliyun.com</span><br></pre></td></tr></table></figure>

<ul>
<li>三台机器定时任务</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crontab -e</span><br></pre></td></tr></table></figure>

<ul>
<li>添加如下内容</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * /usr/sbin/ntpdate ntp4.aliyun.com;</span><br></pre></td></tr></table></figure>

<h5 id="方式二：内网某机器作为时钟同步服务器（推荐，一般生产环境会有内部的统一时钟服务器）"><a href="#方式二：内网某机器作为时钟同步服务器（推荐，一般生产环境会有内部的统一时钟服务器）" class="headerlink" title="方式二：内网某机器作为时钟同步服务器（推荐，一般生产环境会有内部的统一时钟服务器）"></a>方式二：内网某机器作为时钟同步服务器（推荐，一般生产环境会有内部的统一时钟服务器）</h5><ul>
<li><p><font color='red'>以下操作都在root用户下面执行，通过su root切换到root用户</font></p>
</li>
<li><p>以node01（192.168.51.100）这台服务器的时间为准进行时钟同步</p>
</li>
</ul>
<h6 id="第一步-三台机器确定是否安装了ntpd的服务"><a href="#第一步-三台机器确定是否安装了ntpd的服务" class="headerlink" title="第一步:三台机器确定是否安装了ntpd的服务"></a>第一步:三台机器确定是否安装了ntpd的服务</h6><ul>
<li>三台机器确认是否安装ntpdate时钟同步工具</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep ntpdate</span><br></pre></td></tr></table></figure>

<ul>
<li>如果没有安装,三台机器执行以下命令可以进行在线安装</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ntpdate</span><br></pre></td></tr></table></figure>

<ul>
<li>node01安装ntp</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install ntp</span><br></pre></td></tr></table></figure>

<ul>
<li>三台机器，执行以下命令，设置时区为中国上海时区</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">timedatectl set-timezone Asia/Shanghai</span><br></pre></td></tr></table></figure>

<h6 id="第二步：node01启动ntpd服务"><a href="#第二步：node01启动ntpd服务" class="headerlink" title="第二步：node01启动ntpd服务"></a>第二步：node01启动ntpd服务</h6><ul>
<li><p>我们需要启动node01的ntpd服务，作为服务端，对外提供同步时间的服务</p>
</li>
<li><p>启动ntpd的服务</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">启动ntpd服务</span></span><br><span class="line">systemctl start ntpd</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">设置ntpd服务开机启动</span></span><br><span class="line">systemctl enable ntpd</span><br></pre></td></tr></table></figure>

<h6 id="第三步：修改node01服务器配置"><a href="#第三步：修改node01服务器配置" class="headerlink" title="第三步：修改node01服务器配置"></a>第三步：修改node01服务器配置</h6><ul>
<li>修改node01这台服务器的时钟同步配置，允许对外提供服务</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ntp.conf</span><br></pre></td></tr></table></figure>

<ul>
<li><font color='red'>添加以下两行内容</font></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 同意192.168.51.0网段（修改成自己的网段）的所有机器与node01同步时间</span></span><br><span class="line">restrict 192.168.51.0 mask 255.255.255.0 nomodify notrap</span><br><span class="line">server 127.127.1.0</span><br></pre></td></tr></table></figure>

<ul>
<li><font color='red'>注释掉以下这四行内容</font></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 3.centos.pool.ntp.org iburst</span></span><br></pre></td></tr></table></figure>

<ul>
<li>修改完成之后，重启node01的ntpd服务</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart ntpd</span><br></pre></td></tr></table></figure>

<ul>
<li>至此，ntpd的服务端已经安装配置完成，接下来配置客户端与服务端进行同步</li>
</ul>
<h6 id="第四步：配置node02与node03同步node01的时间"><a href="#第四步：配置node02与node03同步node01的时间" class="headerlink" title="第四步：配置node02与node03同步node01的时间"></a>第四步：配置node02与node03同步node01的时间</h6><ul>
<li><p>客户端node02与node03设置时区与node01保持一致Asia/Shanghai</p>
</li>
<li><p>node02与node03修改配置文件，保证每次时间写入硬件时钟</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/ntpdate</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SYNC_HWCLOCK=yes</span><br></pre></td></tr></table></figure>

<ul>
<li>node02与node03修改定时任务，定时与node01同步时间</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crontab -e</span><br></pre></td></tr></table></figure>

<ul>
<li>增加如下内容</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*/1 * * * * /usr/sbin/ntpdate node01</span><br></pre></td></tr></table></figure>


<h4 id="三台机器添加普通用户hadoop"><a href="#三台机器添加普通用户hadoop" class="headerlink" title="三台机器添加普通用户hadoop"></a>三台机器添加普通用户hadoop</h4><ul>
<li>三台linux服务器统一添加普通用户hadoop，并给以sudo权限，用于以后所有的大数据软件的安装</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">useradd hadoop</span><br><span class="line">passwd hadoop</span><br></pre></td></tr></table></figure>

<ul>
<li>三台机器为普通用户添加sudo权限</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">visudo</span><br></pre></td></tr></table></figure>

<ul>
<li>增加如下内容</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop ALL=(ALL)    ALL</span><br></pre></td></tr></table></figure>

<h4 id="三台定义统一目录"><a href="#三台定义统一目录" class="headerlink" title="三台定义统一目录"></a>三台定义统一目录</h4><p>定义三台linux服务器软件压缩包存放目录，以及解压后安装目录，三台机器执行以下命令，创建两个文件夹，一个用于存放软件压缩包目录，一个用于存放解压后目录</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /ap/soft   # 软件压缩包存放目录</span><br><span class="line">mkdir -p /ap/install # 软件解压后存放目录</span><br><span class="line">chown -R hadoop:hadoop /ap  # 将文件夹权限更改为hadoop用户</span><br></pre></td></tr></table></figure>

<ul>
<li><p><font color='red'>创建hadoop用户之后，我们三台机器都通过hadoop用户来进行操作，以后再也不需要使用root用户来操作了</font></p>
</li>
<li><p><font color='red'>三台机器通过 su hadoop命令来切换到hadoop用户</font></p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">su hadoop</span><br></pre></td></tr></table></figure>

<h4 id="三台机器hadoop用户免密码登录"><a href="#三台机器hadoop用户免密码登录" class="headerlink" title="三台机器hadoop用户免密码登录"></a>三台机器hadoop用户免密码登录</h4><ul>
<li><p>重启下3个linux虚拟机，让主机名生效</p>
</li>
<li><p>第一步：三台机器在<font color='red'>hadoop</font>用户下执行以下命令生成公钥与私钥</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure>

<ul>
<li><p><font color='red'>执行上述命令之后，按三次Enter键即可生成了</font></p>
</li>
<li><p>第二步：三台机器在hadoop用户下，执行命令拷贝公钥到node01服务器</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id node01</span><br></pre></td></tr></table></figure>

<ul>
<li><p>第三步：node01服务器将公钥拷贝给node02与node03</p>
</li>
<li><p>node01在hadoop用户下，执行以下命令，将authorized_keys拷贝到node02与node03服务器</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/.ssh/</span><br><span class="line">scp authorized_keys node02:$PWD</span><br><span class="line">scp authorized_keys node03:$PWD</span><br></pre></td></tr></table></figure>

<ul>
<li>第四步：验证；从任意节点是否能免秘钥登陆其他节点；如node01免密登陆node02</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh node02</span><br></pre></td></tr></table></figure>

<h4 id="三台机器关机重启"><a href="#三台机器关机重启" class="headerlink" title="三台机器关机重启"></a>三台机器关机重启</h4><ul>
<li>三台机器在hadoop用户下执行以下命令，实现关机重启</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo reboot -h now</span><br></pre></td></tr></table></figure>

<h4 id="三台机器安装jdk"><a href="#三台机器安装jdk" class="headerlink" title="三台机器安装jdk"></a>三台机器安装jdk</h4><ul>
<li><p>使用hadoop用户来重新连接三台机器，然后使用hadoop用户来安装jdk软件</p>
</li>
<li><p>上传压缩包到第一台服务器的/ap/soft下面，然后进行解压，配置环境变量即可，三台机器都依次安装即可</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /ap/soft/</span><br><span class="line">tar -xzvf jdk-8u141-linux-x64.tar.gz -C /ap/install/</span><br><span class="line">sudo vim /etc/profile</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">添加以下配置内容，配置jdk环境变量</span></span><br><span class="line">export JAVA_HOME=/ap/install/jdk1.8.0</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>

<ul>
<li>让修改马上生效</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>


<h3 id="Hadoop集群的安装"><a href="#Hadoop集群的安装" class="headerlink" title="Hadoop集群的安装"></a>Hadoop集群的安装</h3><ul>
<li>安装环境服务部署规划</li>
</ul>
<table>
<thead>
<tr>
<th>服务器</th>
<th>node01</th>
<th>node02</th>
<th>node03</th>
</tr>
</thead>
<tbody><tr>
<td>HDFS</td>
<td>NameNode</td>
<td></td>
<td></td>
</tr>
<tr>
<td>HDFS</td>
<td>SecondaryNameNode</td>
<td></td>
<td></td>
</tr>
<tr>
<td>HDFS</td>
<td>DataNode</td>
<td>DataNode</td>
<td>DataNode</td>
</tr>
<tr>
<td>YARN</td>
<td>ResourceManager</td>
<td></td>
<td></td>
</tr>
<tr>
<td>YARN</td>
<td>NodeManager</td>
<td>NodeManager</td>
<td>NodeManager</td>
</tr>
<tr>
<td>历史日志服务器</td>
<td>JobHistoryServer</td>
<td></td>
<td></td>
</tr>
</tbody></table>
<h5 id="第一步：上传压缩包并解压"><a href="#第一步：上传压缩包并解压" class="headerlink" title="第一步：上传压缩包并解压"></a>第一步：上传压缩包并解压</h5><ul>
<li>将hadoop包上传到第一台服务器并解压；第一台机器执行以下命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /ap/soft/</span><br><span class="line">tar -xzvf hadoop-3.1.4.tar.gz -C /ap/install</span><br></pre></td></tr></table></figure>

<h5 id="第二步：查看hadoop支持的压缩方式以及本地库"><a href="#第二步：查看hadoop支持的压缩方式以及本地库" class="headerlink" title="第二步：查看hadoop支持的压缩方式以及本地库"></a>第二步：查看hadoop支持的压缩方式以及本地库</h5><ul>
<li>node01执行以下命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /ap/install/hadoop-3.1.4/</span><br><span class="line">bin/hadoop checknative</span><br></pre></td></tr></table></figure>

<ul>
<li>如果出现openssl为false，那么<strong>所有机器</strong>在线安装openssl即可，执行以下命令，虚拟机联网之后就可以在线进行安装了</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install openssl-devel</span><br></pre></td></tr></table></figure>

<h5 id="第三步：修改配置文件"><a href="#第三步：修改配置文件" class="headerlink" title="第三步：修改配置文件"></a>第三步：修改配置文件</h5><h6 id="修改hadoop-env-sh"><a href="#修改hadoop-env-sh" class="headerlink" title="修改hadoop-env.sh"></a>修改hadoop-env.sh</h6><ul>
<li>node01执行以下命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /ap/install/hadoop-3.1.4/etc/hadoop/</span><br><span class="line">vim hadoop-env.sh</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/ap/install/jdk1.8.0</span><br></pre></td></tr></table></figure>

<h6 id="修改core-site-xml"><a href="#修改core-site-xml" class="headerlink" title="修改core-site.xml"></a>修改core-site.xml</h6><ul>
<li>node01执行以下命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim core-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://node01:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/ap/install/hadoop-3.1.4/hadoopDatas/tempDatas<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  缓冲区大小，实际工作中根据服务器性能动态调整；默认值4096 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>io.file.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  开启hdfs的垃圾桶机制，删除掉的数据可以从垃圾桶中回收，单位分钟；默认值0 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.trash.interval<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>10080<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.hadoop.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.hadoop.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.http.staticuser.user<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h6 id="修改hdfs-site-xml"><a href="#修改hdfs-site-xml" class="headerlink" title="修改hdfs-site.xml"></a>修改hdfs-site.xml</h6><ul>
<li>node01执行以下命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim hdfs-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- namenode保存fsimage的路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///ap/install/hadoop-3.1.4/hadoopDatas/namenodeDatas<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--  定义dataNode数据存储的节点位置，实际工作中，一般先确定磁盘的挂载目录，然后多个目录用，进行分割  --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///ap/install/hadoop-3.1.4/hadoopDatas/datanodeDatas<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- namenode保存editslog的目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///ap/install/hadoop-3.1.4/hadoopDatas/dfs/nn/edits<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- secondarynamenode保存待合并的fsimage --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///ap/install/hadoop-3.1.4/hadoopDatas/dfs/snn/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- secondarynamenode保存待合并的editslog --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///ap/install/hadoop-3.1.4/hadoopDatas/dfs/nn/snn/edits<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h6 id="修改mapred-site-xml"><a href="#修改mapred-site-xml" class="headerlink" title="修改mapred-site.xml"></a>修改mapred-site.xml</h6><ul>
<li>node01执行以下命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim mapred-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.ubertask.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=$&#123;HADOOP_HOME&#125;<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>



<h6 id="修改yarn-site-xml"><a href="#修改yarn-site-xml" class="headerlink" title="修改yarn-site.xml"></a>修改yarn-site.xml</h6><ul>
<li>node01执行以下命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim yarn-site.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">   </span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>node01<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>512<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        	<span class="tag">&lt;<span class="name">value</span>&gt;</span>http://node01:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        	<span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        	<span class="tag">&lt;<span class="name">value</span>&gt;</span>25920000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h6 id="修改workers文件"><a href="#修改workers文件" class="headerlink" title="修改workers文件"></a>修改workers文件</h6><ul>
<li>node01执行以下命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim workers</span><br></pre></td></tr></table></figure>

<ul>
<li>原内容替换为</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">node01</span><br><span class="line">node02</span><br><span class="line">node03</span><br></pre></td></tr></table></figure>

<h5 id="第四步：创建文件存放目录"><a href="#第四步：创建文件存放目录" class="headerlink" title="第四步：创建文件存放目录"></a>第四步：创建文件存放目录</h5><ul>
<li>node01上面创建以下目录</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /ap/install/hadoop-3.1.4/hadoopDatas/tempDatas</span><br><span class="line">mkdir -p /ap/install/hadoop-3.1.4/hadoopDatas/namenodeDatas</span><br><span class="line">mkdir -p /ap/install/hadoop-3.1.4/hadoopDatas/datanodeDatas </span><br><span class="line">mkdir -p /ap/install/hadoop-3.1.4/hadoopDatas/dfs/nn/edits</span><br><span class="line">mkdir -p /ap/install/hadoop-3.1.4/hadoopDatas/dfs/snn/name</span><br><span class="line">mkdir -p /ap/install/hadoop-3.1.4/hadoopDatas/dfs/nn/snn/edits</span><br></pre></td></tr></table></figure>

<h5 id="第五步：安装包的分发scp与rsync"><a href="#第五步：安装包的分发scp与rsync" class="headerlink" title="第五步：安装包的分发scp与rsync"></a>第五步：安装包的分发scp与rsync</h5><ul>
<li>在linux当中，用于向远程服务器拷贝文件或者文件夹可以使用scp或者rsync，这两个命令功能类似都是向远程服务器进行拷贝，只不过scp是全量拷贝，rsync可以做到增量拷贝，rsync的效率比scp更高一些</li>
</ul>
<h6 id="1-通过scp直接拷贝"><a href="#1-通过scp直接拷贝" class="headerlink" title="1. 通过scp直接拷贝"></a>1. 通过scp直接拷贝</h6><ul>
<li><p>scp（secure copy）安全拷贝</p>
</li>
<li><p>可以通过scp进行不同服务器之间的文件或者文件夹的复制</p>
</li>
<li><p>使用语法 </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r sourceFile  username@host:destpath</span><br></pre></td></tr></table></figure>
</li>
<li><p>用法示例</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r hadoop-lzo-0.4.20.jar hadoop@node01:/kkb/</span><br></pre></td></tr></table></figure>
</li>
<li><p>node01执行以下命令进行拷贝</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /ap/install/</span><br><span class="line">scp -r hadoop-3.1.4/ node02:$PWD</span><br><span class="line">scp -r hadoop-3.1.4/ node03:$PWD</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h6 id="2-通过rsync来实现增量拷贝"><a href="#2-通过rsync来实现增量拷贝" class="headerlink" title="2. 通过rsync来实现增量拷贝"></a>2. 通过rsync来实现增量拷贝</h6><ul>
<li>rsync 远程同步工具</li>
<li>rsync主要用于备份和镜像。具有速度快、<font color='red'>避免复制相同内容</font>和支持符号链接的优点。</li>
<li><strong>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</strong></li>
<li><font color='red'>三台机器执行以下命令安装rsync工具</font></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install rsync</span><br></pre></td></tr></table></figure>

<ul>
<li><p>基本语法</p>
<ul>
<li>node01执行以下命令同步安装包<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -av /ap/soft/hadoop-3.1.4.tar.gz node02:/ap/soft/</span><br></pre></td></tr></table></figure></li>
<li>命令 [选项参数] 要拷贝的文件路径/名称 目的用户@主机:目的路径/名称</li>
<li>选项参数说明<table>
<thead>
<tr>
<th><strong>选项</strong></th>
<th><strong>功能</strong></th>
</tr>
</thead>
<tbody><tr>
<td>-a</td>
<td>归档拷贝</td>
</tr>
<tr>
<td>-v</td>
<td>显示复制过程</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>把node01机器上的/ap/soft目录同步到node02服务器的hadooop用户下的/ap/目录</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -av /ap/soft node02:/ap/soft</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h6 id="3-通过rsync来封装分发脚本"><a href="#3-通过rsync来封装分发脚本" class="headerlink" title="3. 通过rsync来封装分发脚本"></a>3. 通过rsync来封装分发脚本</h6><p>我们可以通过rsync这个命令工具来实现脚本的分发，可以增量的将文件分发到我们所有其他的机器上面去</p>
<ul>
<li><p> 需求：循环复制文件到所有节点的相同目录下</p>
</li>
<li><p>需求分析：</p>
<ul>
<li>rsync命令原始拷贝：<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -av /ap/soft hadoop@node02:/ap/soft</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>期望脚本使用方式：</p>
<ul>
<li>xsync 要同步的文件名称</li>
<li>说明：在/home/hadoop/bin这个目录下存放的脚本，hadoop用户可以在系统任何地方直接执行。</li>
</ul>
</li>
<li><p>脚本实现</p>
<ul>
<li><p>在/home/hadoop目录下创建bin目录，并在bin目录下xsync创建文件，文件内容如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd ~</span><br><span class="line">mkdir bin</span><br><span class="line">cd /home/hadoop/bin</span><br><span class="line">touch xsync</span><br><span class="line">vim xsync</span><br></pre></td></tr></table></figure></li>
<li><p>在该文件中编写如下代码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1 获取输入参数个数，如果没有参数，直接退出</span></span><br><span class="line">pcount=$#</span><br><span class="line">if ((pcount==0)); then</span><br><span class="line">echo no args;</span><br><span class="line">exit;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">2 获取文件名称</span></span><br><span class="line">p1=$1</span><br><span class="line">fname=`basename $p1`</span><br><span class="line"></span><br><span class="line">echo $fname</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">3 获取上级目录到绝对路径</span></span><br><span class="line">pdir=`cd -P $(dirname $p1); pwd`</span><br><span class="line">echo $pdir</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">4 获取当前用户名称</span></span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">5 循环</span></span><br><span class="line">for((host=1; host&lt;4; host++)); do</span><br><span class="line">    echo ------------------- node0$host --------------</span><br><span class="line">    rsync -av $pdir/$fname $user@node0$host:$pdir</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改脚本 xsync 具有执行权限</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/bin/</span><br><span class="line">chmod 777 xsync</span><br></pre></td></tr></table></figure>
</li>
<li><p>调用脚本形式：xsync 文件名称</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xsync /home/hadoop/bin/</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<h5 id="第六步：配置hadoop的环境变量"><a href="#第六步：配置hadoop的环境变量" class="headerlink" title="第六步：配置hadoop的环境变量"></a>第六步：配置hadoop的环境变量</h5><ul>
<li>三台机器都要进行配置hadoop的环境变量</li>
<li>三台机器执行以下命令</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/profile</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/ap/install/hadoop-3.1.4</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<ul>
<li>配置完成之后生效</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<h5 id="第七步：格式化集群"><a href="#第七步：格式化集群" class="headerlink" title="第七步：格式化集群"></a>第七步：格式化集群</h5><ul>
<li>要启动 Hadoop 集群，需要启动 HDFS 和 YARN 两个集群。 </li>
<li><strong>注意：首次启动HDFS时，必须对其进行格式化操作。本质上是一些清理和准备工作，因为此时的 HDFS 在物理上还是不存在的。<font color='red'>格式化操作只有在首次启动的时候需要，以后再也不需要了</font></strong></li>
<li><font color='red'>node01执行一遍即可</font></li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure>

<h5 id="第八步：集群启动"><a href="#第八步：集群启动" class="headerlink" title="第八步：集群启动"></a>第八步：集群启动</h5><ul>
<li>启动集群有两种方式：<ul>
<li>脚本一键启动</li>
<li>单个进程逐个启动</li>
</ul>
</li>
</ul>
<h6 id="1-启动HDFS、YARN、Historyserver"><a href="#1-启动HDFS、YARN、Historyserver" class="headerlink" title="1. 启动HDFS、YARN、Historyserver"></a>1. 启动HDFS、YARN、Historyserver</h6><ul>
<li><p>如果配置了 etc/hadoop/workers 和 ssh 免密登录，则可以使用程序脚本启动所有 Hadoop 两个集群的相关进程，在主节点所设定的机器上执行。</p>
</li>
<li><p>启动集群</p>
</li>
<li><p>主节点node01节点上执行以下命令</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br><span class="line">start-yarn.sh</span><br><span class="line">mapred --daemon start historyserver</span><br></pre></td></tr></table></figure>

<ul>
<li>停止集群（主节点node01节点上执行）：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">stop-dfs.sh</span><br><span class="line">stop-yarn.sh</span><br><span class="line">mapred --daemon stop historyserver</span><br></pre></td></tr></table></figure>


<h6 id="2-单个进程逐个启动"><a href="#2-单个进程逐个启动" class="headerlink" title="2. 单个进程逐个启动"></a>2. 单个进程逐个启动</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在主节点上使用以下命令启动 HDFS NameNode：</span> </span><br><span class="line">hdfs --daemon start namenode</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在主节点上使用以下命令启动 HDFS SecondaryNamenode：</span> </span><br><span class="line">hdfs --daemon start secondarynamenode</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在每个从节点上使用以下命令启动 HDFS DataNode：</span> </span><br><span class="line">hdfs --daemon start datanode</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在主节点上使用以下命令启动 YARN ResourceManager：</span> </span><br><span class="line">yarn --daemon start resourcemanager</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在每个从节点上使用以下命令启动 YARN nodemanager：</span> </span><br><span class="line">yarn --daemon start nodemanager</span><br></pre></td></tr></table></figure>

<ul>
<li>以上脚本位于$HADOOP_HOME/sbin/目录下。如果想要停止某个节点上某个角色，只需要把命令中的start 改为stop 即可。</li>
</ul>
<h6 id="3-一键启动hadoop集群的脚本"><a href="#3-一键启动hadoop集群的脚本" class="headerlink" title="3. 一键启动hadoop集群的脚本"></a>3. 一键启动hadoop集群的脚本</h6><ul>
<li><p>为了便于一键启动hadoop集群，我们可以编写shell脚本</p>
</li>
<li><p>在node01服务器的/home/hadoop/bin目录下创建脚本</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /home/hadoop/bin/</span><br><span class="line">vim hadoop.sh</span><br></pre></td></tr></table></figure>

<ul>
<li>内容如下</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot; )&#123;</span><br><span class="line">    source /etc/profile;</span><br><span class="line">    /ap/install/hadoop-3.1.4/sbin/start-dfs.sh</span><br><span class="line">    /ap/install/hadoop-3.1.4/sbin/start-yarn.sh</span><br><span class="line">    #/ap/install/hadoop-3.1.4/sbin/mr-jobhistory-daemon.sh start historyserver</span><br><span class="line">    /ap/install/hadoop-3.1.4/bin/mapred --daemon start historyserver</span><br><span class="line">&#125;;;</span><br><span class="line">&quot;stop&quot;)&#123;</span><br><span class="line">    /ap/install/hadoop-3.1.4/sbin/stop-dfs.sh</span><br><span class="line">    /ap/install/hadoop-3.1.4/sbin/stop-yarn.sh</span><br><span class="line">    #/ap/install/hadoop-3.1.4/sbin/mr-jobhistory-daemon.sh stop  historyserver</span><br><span class="line">    /ap/install/hadoop-3.1.4/bin/mapred --daemon stop historyserver</span><br><span class="line">&#125;;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>

<ul>
<li>修改脚本权限</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 hadoop.sh</span><br><span class="line">sh hadoop.sh start  # 启动hadoop集群</span><br><span class="line">sh hadoop.sh stop   # 停止hadoop集群</span><br></pre></td></tr></table></figure>

<h5 id="第九步：验证集群是否搭建成功"><a href="#第九步：验证集群是否搭建成功" class="headerlink" title="第九步：验证集群是否搭建成功"></a>第九步：验证集群是否搭建成功</h5><h6 id="1-访问web-ui界面"><a href="#1-访问web-ui界面" class="headerlink" title="1. 访问web ui界面"></a>1. 访问web ui界面</h6><ul>
<li><p>hdfs集群访问地址<br><a target="_blank" rel="noopener" href="http://192.168.51.100:9870/">http://192.168.51.100:9870/</a></p>
</li>
<li><p>yarn集群访问地址<br><a target="_blank" rel="noopener" href="http://192.168.51.100:8088/">http://192.168.51.100:8088</a></p>
</li>
<li><p>jobhistory访问地址：<br><a target="_blank" rel="noopener" href="http://192.168.51.100:19888/">http://192.168.51.100:19888</a></p>
</li>
<li><p>若将linux的<code>/etc/hosts</code>文件的如下内容，添加到本机的hosts文件中，<strong>ip地址根据自己的实际情况进行修改</strong></p>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.51.100 node01.hadoop.com node01</span><br><span class="line">192.168.51.110 node02.hadoop.com node02</span><br><span class="line">192.168.51.120 node03.hadoop.com node03</span><br></pre></td></tr></table></figure>

<ul>
<li>windows的hosts文件路径是<code>C:\Windows\System32\drivers\etc\hosts</code></li>
<li>mac的hosts文件是<code>/etc/hosts</code></li>
<li>那么，上边的web ui界面访问地址可以分别改成<ul>
<li>hdfs集群访问地址<br><a target="_blank" rel="noopener" href="http://node01:9870/">http://node01:9870/</a></li>
<li>yarn集群访问地址<br><a target="_blank" rel="noopener" href="http://node01:8088/">http://node01:8088</a></li>
<li>jobhistory访问地址：<br><a target="_blank" rel="noopener" href="http://node01:19888/">http://node01:19888</a></li>
</ul>
</li>
</ul>
<h6 id="2-所有机器查看进程脚本"><a href="#2-所有机器查看进程脚本" class="headerlink" title="2. 所有机器查看进程脚本"></a>2. 所有机器查看进程脚本</h6><ul>
<li>我们也可以通过jps在每台机器上面查看进程名称，为了方便我们以后查看进程，我们可以通过脚本一键查看所有机器的进程</li>
<li>在node01服务器的/home/hadoop/bin目录下创建文件xcall</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/bin/</span><br><span class="line">vim xcall</span><br></pre></td></tr></table></figure>

<ul>
<li>添加以下内容</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">params=$@</span><br><span class="line">for (( i=1 ; i &lt;= 3 ; i = $i + 1 )) ; do</span><br><span class="line">    echo ============= node0$i $params =============</span><br><span class="line">    ssh node0$i &quot;source /etc/profile;$params&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<ul>
<li>然后一键查看进程并分发该脚本</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 ~/bin/xcall</span><br><span class="line">xsync ~/bin/</span><br></pre></td></tr></table></figure>

<ul>
<li>各节点应该启动的hadoop进程如下图</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">xcall jps</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 bin]$ xcall jps</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; node01 jps &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">75378 JobHistoryServer</span><br><span class="line">74357 DataNode</span><br><span class="line">74183 NameNode</span><br><span class="line">74823 ResourceManager</span><br><span class="line">74569 SecondaryNameNode</span><br><span class="line">75149 NodeManager</span><br><span class="line">95869 Jps</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; node02 jps &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">17975 DataNode</span><br><span class="line">18089 NodeManager</span><br><span class="line">22620 Jps</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D; node03 jps &#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">7474 DataNode</span><br><span class="line">7592 NodeManager</span><br><span class="line">34632 Jps</span><br></pre></td></tr></table></figure>

<h6 id="3-运行一个mr例子"><a href="#3-运行一个mr例子" class="headerlink" title="3. 运行一个mr例子"></a>3. 运行一个mr例子</h6><ul>
<li>任一节点运行pi例子</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@node01 ~]$ hadoop jar &#x2F;ap&#x2F;install&#x2F;hadoop-3.1.4&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.4.jar pi 5 5</span><br></pre></td></tr></table></figure>

<ul>
<li>图片案例补充</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">Number of Maps  &#x3D; 5</span><br><span class="line">Samples per Map &#x3D; 5</span><br><span class="line">Wrote input for Map #0</span><br><span class="line">Wrote input for Map #1</span><br><span class="line">Wrote input for Map #2</span><br><span class="line">Wrote input for Map #3</span><br><span class="line">Wrote input for Map #4</span><br><span class="line">Starting Job</span><br><span class="line">2021-08-02 22:40:24,029 INFO client.RMProxy: Connecting to ResourceManager at node01&#x2F;192.168.51.100:8032</span><br><span class="line">2021-08-02 22:40:24,560 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: &#x2F;tmp&#x2F;hadoop-yarn&#x2F;staging&#x2F;hadoop&#x2F;.staging&#x2F;job_1627825163377_0002</span><br><span class="line">2021-08-02 22:40:24,684 INFO input.FileInputFormat: Total input files to process : 5</span><br><span class="line">2021-08-02 22:40:24,735 INFO mapreduce.JobSubmitter: number of splits:5</span><br><span class="line">2021-08-02 22:40:24,847 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1627825163377_0002</span><br><span class="line">2021-08-02 22:40:24,848 INFO mapreduce.JobSubmitter: Executing with tokens: []</span><br><span class="line">2021-08-02 22:40:24,966 INFO conf.Configuration: resource-types.xml not found</span><br><span class="line">2021-08-02 22:40:24,966 INFO resource.ResourceUtils: Unable to find &#39;resource-types.xml&#39;.</span><br><span class="line">2021-08-02 22:40:25,015 INFO impl.YarnClientImpl: Submitted application application_1627825163377_0002</span><br><span class="line">2021-08-02 22:40:25,042 INFO mapreduce.Job: The url to track the job: http:&#x2F;&#x2F;node01:8088&#x2F;proxy&#x2F;application_1627825163377_0002&#x2F;</span><br><span class="line">2021-08-02 22:40:25,043 INFO mapreduce.Job: Running job: job_1627825163377_0002</span><br><span class="line">2021-08-02 22:40:31,159 INFO mapreduce.Job: Job job_1627825163377_0002 running in uber mode : true</span><br><span class="line">2021-08-02 22:40:31,168 INFO mapreduce.Job:  map 40% reduce 0%</span><br><span class="line">2021-08-02 22:40:32,263 INFO mapreduce.Job:  map 60% reduce 0%</span><br><span class="line">2021-08-02 22:40:33,269 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">2021-08-02 22:40:34,273 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">2021-08-02 22:40:35,287 INFO mapreduce.Job: Job job_1627825163377_0002 completed successfully</span><br><span class="line">2021-08-02 22:40:35,351 INFO mapreduce.Job: Counters: 56</span><br><span class="line">        File System Counters</span><br><span class="line">                FILE: Number of bytes read&#x3D;416</span><br><span class="line">                FILE: Number of bytes written&#x3D;1316</span><br><span class="line">                FILE: Number of read operations&#x3D;0</span><br><span class="line">                FILE: Number of large read operations&#x3D;0</span><br><span class="line">                FILE: Number of write operations&#x3D;0</span><br><span class="line">                HDFS: Number of bytes read&#x3D;7052</span><br><span class="line">                HDFS: Number of bytes written&#x3D;1425544</span><br><span class="line">                HDFS: Number of read operations&#x3D;163</span><br><span class="line">                HDFS: Number of large read operations&#x3D;0</span><br><span class="line">                HDFS: Number of write operations&#x3D;21</span><br><span class="line">        Job Counters</span><br><span class="line">                Launched map tasks&#x3D;5</span><br><span class="line">                Launched reduce tasks&#x3D;1</span><br><span class="line">                Other local map tasks&#x3D;5</span><br><span class="line">                Total time spent by all maps in occupied slots (ms)&#x3D;0</span><br><span class="line">                Total time spent by all reduces in occupied slots (ms)&#x3D;0</span><br><span class="line">                TOTAL_LAUNCHED_UBERTASKS&#x3D;6</span><br><span class="line">                NUM_UBER_SUBMAPS&#x3D;5</span><br><span class="line">                NUM_UBER_SUBREDUCES&#x3D;1</span><br><span class="line">                Total time spent by all map tasks (ms)&#x3D;1616</span><br><span class="line">                Total time spent by all reduce tasks (ms)&#x3D;1271</span><br><span class="line">                Total vcore-milliseconds taken by all map tasks&#x3D;0</span><br><span class="line">                Total vcore-milliseconds taken by all reduce tasks&#x3D;0</span><br><span class="line">                Total megabyte-milliseconds taken by all map tasks&#x3D;0</span><br><span class="line">                Total megabyte-milliseconds taken by all reduce tasks&#x3D;0</span><br><span class="line">        Map-Reduce Framework</span><br><span class="line">                Map input records&#x3D;5</span><br><span class="line">                Map output records&#x3D;10</span><br><span class="line">                Map output bytes&#x3D;90</span><br><span class="line">                Map output materialized bytes&#x3D;140</span><br><span class="line">                Input split bytes&#x3D;720</span><br><span class="line">                Combine input records&#x3D;0</span><br><span class="line">                Combine output records&#x3D;0</span><br><span class="line">                Reduce input groups&#x3D;2</span><br><span class="line">                Reduce shuffle bytes&#x3D;140</span><br><span class="line">                Reduce input records&#x3D;10</span><br><span class="line">                Reduce output records&#x3D;0</span><br><span class="line">                Spilled Records&#x3D;20</span><br><span class="line">                Shuffled Maps &#x3D;5</span><br><span class="line">                Failed Shuffles&#x3D;0</span><br><span class="line">                Merged Map outputs&#x3D;5</span><br><span class="line">                GC time elapsed (ms)&#x3D;105</span><br><span class="line">                CPU time spent (ms)&#x3D;2320</span><br><span class="line">                Physical memory (bytes) snapshot&#x3D;4011163648</span><br><span class="line">                Virtual memory (bytes) snapshot&#x3D;17474719744</span><br><span class="line">                Total committed heap usage (bytes)&#x3D;3146776576</span><br><span class="line">                Peak Map Physical memory (bytes)&#x3D;833974272</span><br><span class="line">                Peak Map Virtual memory (bytes)&#x3D;2911576064</span><br><span class="line">                Peak Reduce Physical memory (bytes)&#x3D;856629248</span><br><span class="line">                Peak Reduce Virtual memory (bytes)&#x3D;2919997440</span><br><span class="line">        Shuffle Errors</span><br><span class="line">                BAD_ID&#x3D;0</span><br><span class="line">                CONNECTION&#x3D;0</span><br><span class="line">                IO_ERROR&#x3D;0</span><br><span class="line">                WRONG_LENGTH&#x3D;0</span><br><span class="line">                WRONG_MAP&#x3D;0</span><br><span class="line">                WRONG_REDUCE&#x3D;0</span><br><span class="line">        File Input Format Counters</span><br><span class="line">                Bytes Read&#x3D;590</span><br><span class="line">        File Output Format Counters</span><br><span class="line">                Bytes Written&#x3D;97</span><br><span class="line">Job Finished in 11.376 seconds</span><br><span class="line">Estimated value of Pi is 3.68000000000000000000</span><br></pre></td></tr></table></figure>

<ul>
<li>yarn集群访问地址<br><a target="_blank" rel="noopener" href="http://node01:8088/">http://node01:8088</a></li>
</ul>
<p><img src="/images/hadoop/hadoop_cluster.png" alt="hadoop_cluster"></p>
<ul>
<li>hdfs集群访问地址<br><a target="_blank" rel="noopener" href="http://node01:9870/">http://node01:9870/</a></li>
</ul>
<p><img src="/images/hadoop/hadoop_overview.png" alt="hadoop_overview"></p>
<p><img src="/images/hadoop/hadoop_summary.png" alt="hadoop_summary"></p>
<ul>
<li>jobhistory访问地址：<br><a target="_blank" rel="noopener" href="http://node01:19888/">http://node01:19888</a></li>
</ul>
<p><img src="/images/hadoop/hadoop_jobhistory.png" alt="hadoop_jobhistory"></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Linux/" rel="tag"># Linux</a>
              <a href="/tags/cluster/" rel="tag"># cluster</a>
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/11/21/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" rel="prev" title="数据仓库">
      <i class="fa fa-chevron-left"></i> 数据仓库
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/12/04/ZooKeeper%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/" rel="next" title="ZooKeeper集群部署">
      ZooKeeper集群部署 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadoop%E6%98%AF%E4%B8%80%E7%A7%8D%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%92%8C%E8%AE%A1%E7%AE%97%E7%9A%84%E6%A1%86%E6%9E%B6%E3%80%82"><span class="nav-number">1.</span> <span class="nav-text">Hadoop是一种分布式数据和计算的框架。</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE"><span class="nav-number">1.1.</span> <span class="nav-text">服务器基础配置</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E6%9B%B4%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%90%8D"><span class="nav-number">1.1.1.</span> <span class="nav-text">三台机器更改主机名</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E5%81%9A%E4%B8%BB%E6%9C%BA%E5%90%8D%E4%B8%8EIP%E5%9C%B0%E5%9D%80%E7%9A%84%E6%98%A0%E5%B0%84"><span class="nav-number">1.1.2.</span> <span class="nav-text">三台机器做主机名与IP地址的映射</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E6%97%B6%E9%92%9F%E5%90%8C%E6%AD%A5"><span class="nav-number">1.1.3.</span> <span class="nav-text">三台机器时钟同步</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B9%E5%BC%8F%E4%B8%80%EF%BC%9A%E9%80%9A%E8%BF%87%E7%BD%91%E7%BB%9C%E8%BF%9B%E8%A1%8C%E6%97%B6%E9%92%9F%E5%90%8C%E6%AD%A5"><span class="nav-number">1.1.3.1.</span> <span class="nav-text">方式一：通过网络进行时钟同步</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%96%B9%E5%BC%8F%E4%BA%8C%EF%BC%9A%E5%86%85%E7%BD%91%E6%9F%90%E6%9C%BA%E5%99%A8%E4%BD%9C%E4%B8%BA%E6%97%B6%E9%92%9F%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%88%E6%8E%A8%E8%8D%90%EF%BC%8C%E4%B8%80%E8%88%AC%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%BC%9A%E6%9C%89%E5%86%85%E9%83%A8%E7%9A%84%E7%BB%9F%E4%B8%80%E6%97%B6%E9%92%9F%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%89"><span class="nav-number">1.1.3.2.</span> <span class="nav-text">方式二：内网某机器作为时钟同步服务器（推荐，一般生产环境会有内部的统一时钟服务器）</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5-%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E7%A1%AE%E5%AE%9A%E6%98%AF%E5%90%A6%E5%AE%89%E8%A3%85%E4%BA%86ntpd%E7%9A%84%E6%9C%8D%E5%8A%A1"><span class="nav-number">1.1.3.2.1.</span> <span class="nav-text">第一步:三台机器确定是否安装了ntpd的服务</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9Anode01%E5%90%AF%E5%8A%A8ntpd%E6%9C%8D%E5%8A%A1"><span class="nav-number">1.1.3.2.2.</span> <span class="nav-text">第二步：node01启动ntpd服务</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E4%BF%AE%E6%94%B9node01%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE"><span class="nav-number">1.1.3.2.3.</span> <span class="nav-text">第三步：修改node01服务器配置</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A%E9%85%8D%E7%BD%AEnode02%E4%B8%8Enode03%E5%90%8C%E6%AD%A5node01%E7%9A%84%E6%97%B6%E9%97%B4"><span class="nav-number">1.1.3.2.4.</span> <span class="nav-text">第四步：配置node02与node03同步node01的时间</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E6%B7%BB%E5%8A%A0%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7hadoop"><span class="nav-number">1.1.4.</span> <span class="nav-text">三台机器添加普通用户hadoop</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E5%8F%B0%E5%AE%9A%E4%B9%89%E7%BB%9F%E4%B8%80%E7%9B%AE%E5%BD%95"><span class="nav-number">1.1.5.</span> <span class="nav-text">三台定义统一目录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8hadoop%E7%94%A8%E6%88%B7%E5%85%8D%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95"><span class="nav-number">1.1.6.</span> <span class="nav-text">三台机器hadoop用户免密码登录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E5%85%B3%E6%9C%BA%E9%87%8D%E5%90%AF"><span class="nav-number">1.1.7.</span> <span class="nav-text">三台机器关机重启</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%89%E5%8F%B0%E6%9C%BA%E5%99%A8%E5%AE%89%E8%A3%85jdk"><span class="nav-number">1.1.8.</span> <span class="nav-text">三台机器安装jdk</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Hadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E8%A3%85"><span class="nav-number">1.2.</span> <span class="nav-text">Hadoop集群的安装</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E4%B8%8A%E4%BC%A0%E5%8E%8B%E7%BC%A9%E5%8C%85%E5%B9%B6%E8%A7%A3%E5%8E%8B"><span class="nav-number">1.2.0.1.</span> <span class="nav-text">第一步：上传压缩包并解压</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E6%9F%A5%E7%9C%8Bhadoop%E6%94%AF%E6%8C%81%E7%9A%84%E5%8E%8B%E7%BC%A9%E6%96%B9%E5%BC%8F%E4%BB%A5%E5%8F%8A%E6%9C%AC%E5%9C%B0%E5%BA%93"><span class="nav-number">1.2.0.2.</span> <span class="nav-text">第二步：查看hadoop支持的压缩方式以及本地库</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="nav-number">1.2.0.3.</span> <span class="nav-text">第三步：修改配置文件</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9hadoop-env-sh"><span class="nav-number">1.2.0.3.1.</span> <span class="nav-text">修改hadoop-env.sh</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9core-site-xml"><span class="nav-number">1.2.0.3.2.</span> <span class="nav-text">修改core-site.xml</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9hdfs-site-xml"><span class="nav-number">1.2.0.3.3.</span> <span class="nav-text">修改hdfs-site.xml</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9mapred-site-xml"><span class="nav-number">1.2.0.3.4.</span> <span class="nav-text">修改mapred-site.xml</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9yarn-site-xml"><span class="nav-number">1.2.0.3.5.</span> <span class="nav-text">修改yarn-site.xml</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#%E4%BF%AE%E6%94%B9workers%E6%96%87%E4%BB%B6"><span class="nav-number">1.2.0.3.6.</span> <span class="nav-text">修改workers文件</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E5%9B%9B%E6%AD%A5%EF%BC%9A%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%E5%AD%98%E6%94%BE%E7%9B%AE%E5%BD%95"><span class="nav-number">1.2.0.4.</span> <span class="nav-text">第四步：创建文件存放目录</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E4%BA%94%E6%AD%A5%EF%BC%9A%E5%AE%89%E8%A3%85%E5%8C%85%E7%9A%84%E5%88%86%E5%8F%91scp%E4%B8%8Ersync"><span class="nav-number">1.2.0.5.</span> <span class="nav-text">第五步：安装包的分发scp与rsync</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-%E9%80%9A%E8%BF%87scp%E7%9B%B4%E6%8E%A5%E6%8B%B7%E8%B4%9D"><span class="nav-number">1.2.0.5.1.</span> <span class="nav-text">1. 通过scp直接拷贝</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-%E9%80%9A%E8%BF%87rsync%E6%9D%A5%E5%AE%9E%E7%8E%B0%E5%A2%9E%E9%87%8F%E6%8B%B7%E8%B4%9D"><span class="nav-number">1.2.0.5.2.</span> <span class="nav-text">2. 通过rsync来实现增量拷贝</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-%E9%80%9A%E8%BF%87rsync%E6%9D%A5%E5%B0%81%E8%A3%85%E5%88%86%E5%8F%91%E8%84%9A%E6%9C%AC"><span class="nav-number">1.2.0.5.3.</span> <span class="nav-text">3. 通过rsync来封装分发脚本</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E5%85%AD%E6%AD%A5%EF%BC%9A%E9%85%8D%E7%BD%AEhadoop%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="nav-number">1.2.0.6.</span> <span class="nav-text">第六步：配置hadoop的环境变量</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E4%B8%83%E6%AD%A5%EF%BC%9A%E6%A0%BC%E5%BC%8F%E5%8C%96%E9%9B%86%E7%BE%A4"><span class="nav-number">1.2.0.7.</span> <span class="nav-text">第七步：格式化集群</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E5%85%AB%E6%AD%A5%EF%BC%9A%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8"><span class="nav-number">1.2.0.8.</span> <span class="nav-text">第八步：集群启动</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-%E5%90%AF%E5%8A%A8HDFS%E3%80%81YARN%E3%80%81Historyserver"><span class="nav-number">1.2.0.8.1.</span> <span class="nav-text">1. 启动HDFS、YARN、Historyserver</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-%E5%8D%95%E4%B8%AA%E8%BF%9B%E7%A8%8B%E9%80%90%E4%B8%AA%E5%90%AF%E5%8A%A8"><span class="nav-number">1.2.0.8.2.</span> <span class="nav-text">2. 单个进程逐个启动</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-%E4%B8%80%E9%94%AE%E5%90%AF%E5%8A%A8hadoop%E9%9B%86%E7%BE%A4%E7%9A%84%E8%84%9A%E6%9C%AC"><span class="nav-number">1.2.0.8.3.</span> <span class="nav-text">3. 一键启动hadoop集群的脚本</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E7%AC%AC%E4%B9%9D%E6%AD%A5%EF%BC%9A%E9%AA%8C%E8%AF%81%E9%9B%86%E7%BE%A4%E6%98%AF%E5%90%A6%E6%90%AD%E5%BB%BA%E6%88%90%E5%8A%9F"><span class="nav-number">1.2.0.9.</span> <span class="nav-text">第九步：验证集群是否搭建成功</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-%E8%AE%BF%E9%97%AEweb-ui%E7%95%8C%E9%9D%A2"><span class="nav-number">1.2.0.9.1.</span> <span class="nav-text">1. 访问web ui界面</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-%E6%89%80%E6%9C%89%E6%9C%BA%E5%99%A8%E6%9F%A5%E7%9C%8B%E8%BF%9B%E7%A8%8B%E8%84%9A%E6%9C%AC"><span class="nav-number">1.2.0.9.2.</span> <span class="nav-text">2. 所有机器查看进程脚本</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-%E8%BF%90%E8%A1%8C%E4%B8%80%E4%B8%AAmr%E4%BE%8B%E5%AD%90"><span class="nav-number">1.2.0.9.3.</span> <span class="nav-text">3. 运行一个mr例子</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">guozenghuang</p>
  <div class="site-description" itemprop="description">一个94年程序员的个人学习小站</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">31</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">30</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">闽ICP备19024033号 </a>
  </div>

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">guozenghuang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
